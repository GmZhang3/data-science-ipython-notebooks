{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack-blend-lrs-xgb-lgb-house-prices-k-v17](https://www.kaggle.com/itslek/stack-blend-lrs-xgb-lgb-house-prices-k-v17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.stats import skew                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import os\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./data/all\"))\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1460, 81)\n",
      "Test set size: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/all/train.csv')\n",
    "test = pd.read_csv('./data/all/test.csv')\n",
    "print(\"Train set size:\", train.shape)\n",
    "print(\"Test set size:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析工作..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
      "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "\n",
      "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0      2   2008        WD         Normal     208500  \n",
      "1      5   2007        WD         Normal     181500  \n",
      "2      9   2008        WD         Normal     223500  \n",
      "3      2   2006        WD        Abnorml     140000  \n",
      "4     12   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START data processing 2019-03-20 20:10:13.490665\n",
      "(1458, 80)\n"
     ]
    }
   ],
   "source": [
    "print('START data processing', datetime.now(), )\n",
    "\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# Deleting outliers\n",
    "train = train[train.GrLivArea < 4500]#数据分析,箱线图，直方图，发现GrLivArea特征大于4500认为是outliers\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 80)\n"
     ]
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])#取自然对数，将很大的数压缩\n",
    "# train[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 79)\n"
     ]
    }
   ],
   "source": [
    "y = train.SalePrice.reset_index(drop=True)\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test\n",
    "\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n",
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "\n",
    "features['Functional'] = features['Functional'].fillna('Typ')#众数\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\")#众数\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")#KitchenQual不缺失啊？\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])#出现频率最高的类别来填充\n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])#出现频率最高的类别来填充\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])#不缺失啊？\n",
    "\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")#缺失过多，置为缺失\n",
    "\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x7fceb3d984a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.groupby('MSSubClass')['MSZoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 86)\n"
     ]
    }
   ],
   "source": [
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "\n",
    "features.update(features[objects].fillna('None'))\n",
    "\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Filling in the rest of the NA's\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\n",
    "\n",
    "features = features.drop(['Utilities', 'Street', 'PoolQC', ], axis=1)#Utilities，Street特征取值无鉴别性；PoolQC缺失过多\n",
    "\n",
    "features['YrBltAndRemod'] = features['YearBuilt'] + features['YearRemodAdd']\n",
    "features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])\n",
    "\n",
    "# simplified features\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 309)\n"
     ]
    }
   ],
   "source": [
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "print(final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1458, 309) y (1458,) X_sub (1459, 309)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
       "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
       "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'YrBltAndRemod', 'TotalSF',\n",
       "       'Total_sqr_footage', 'Total_Bathrooms', 'Total_porch_sf',\n",
       "       'haspool', 'has2ndfloor', 'hasgarage', 'hasbsmt', 'hasfireplace',\n",
       "       'MSZoning_C (all)', 'MSZoning_FV', 'MSZoning_RH', 'MSZoning_RL',\n",
       "       'MSZoning_RM', 'Alley_Grvl', 'Alley_None', 'Alley_Pave',\n",
       "       'LotShape_IR1', 'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg',\n",
       "       'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low',\n",
       "       'LandContour_Lvl', 'LotConfig_Corner', 'LotConfig_CulDSac',\n",
       "       'LotConfig_FR2', 'LotConfig_FR3', 'LotConfig_Inside',\n",
       "       'LandSlope_Gtl', 'LandSlope_Mod', 'LandSlope_Sev',\n",
       "       'Neighborhood_Blmngtn', 'Neighborhood_Blueste',\n",
       "       'Neighborhood_BrDale', 'Neighborhood_BrkSide',\n",
       "       'Neighborhood_ClearCr', 'Neighborhood_CollgCr',\n",
       "       'Neighborhood_Crawfor', 'Neighborhood_Edwards',\n",
       "       'Neighborhood_Gilbert', 'Neighborhood_IDOTRR',\n",
       "       'Neighborhood_MeadowV', 'Neighborhood_Mitchel',\n",
       "       'Neighborhood_NAmes', 'Neighborhood_NPkVill',\n",
       "       'Neighborhood_NWAmes', 'Neighborhood_NoRidge',\n",
       "       'Neighborhood_NridgHt', 'Neighborhood_OldTown',\n",
       "       'Neighborhood_SWISU', 'Neighborhood_Sawyer',\n",
       "       'Neighborhood_SawyerW', 'Neighborhood_Somerst',\n",
       "       'Neighborhood_StoneBr', 'Neighborhood_Timber',\n",
       "       'Neighborhood_Veenker', 'Condition1_Artery', 'Condition1_Feedr',\n",
       "       'Condition1_Norm', 'Condition1_PosA', 'Condition1_PosN',\n",
       "       'Condition1_RRAe', 'Condition1_RRAn', 'Condition1_RRNe',\n",
       "       'Condition1_RRNn', 'Condition2_Artery', 'Condition2_Feedr',\n",
       "       'Condition2_Norm', 'Condition2_PosA', 'Condition2_PosN',\n",
       "       'Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn',\n",
       "       'BldgType_1Fam', 'BldgType_2fmCon', 'BldgType_Duplex',\n",
       "       'BldgType_Twnhs', 'BldgType_TwnhsE', 'HouseStyle_1.5Fin',\n",
       "       'HouseStyle_1.5Unf', 'HouseStyle_1Story', 'HouseStyle_2.5Fin',\n",
       "       'HouseStyle_2.5Unf', 'HouseStyle_2Story', 'HouseStyle_SFoyer',\n",
       "       'HouseStyle_SLvl', 'RoofStyle_Flat', 'RoofStyle_Gable',\n",
       "       'RoofStyle_Gambrel', 'RoofStyle_Hip', 'RoofStyle_Mansard',\n",
       "       'RoofStyle_Shed', 'RoofMatl_CompShg', 'RoofMatl_Membran',\n",
       "       'RoofMatl_Metal', 'RoofMatl_Roll', 'RoofMatl_Tar&Grv',\n",
       "       'RoofMatl_WdShake', 'RoofMatl_WdShngl', 'Exterior1st_AsbShng',\n",
       "       'Exterior1st_AsphShn', 'Exterior1st_BrkComm',\n",
       "       'Exterior1st_BrkFace', 'Exterior1st_CBlock', 'Exterior1st_CemntBd',\n",
       "       'Exterior1st_HdBoard', 'Exterior1st_ImStucc',\n",
       "       'Exterior1st_MetalSd', 'Exterior1st_None', 'Exterior1st_Plywood',\n",
       "       'Exterior1st_Stone', 'Exterior1st_Stucco', 'Exterior1st_VinylSd',\n",
       "       'Exterior1st_Wd Sdng', 'Exterior1st_WdShing',\n",
       "       'Exterior2nd_AsbShng', 'Exterior2nd_AsphShn',\n",
       "       'Exterior2nd_Brk Cmn', 'Exterior2nd_BrkFace', 'Exterior2nd_CBlock',\n",
       "       'Exterior2nd_CmentBd', 'Exterior2nd_HdBoard',\n",
       "       'Exterior2nd_ImStucc', 'Exterior2nd_MetalSd', 'Exterior2nd_None',\n",
       "       'Exterior2nd_Other', 'Exterior2nd_Plywood', 'Exterior2nd_Stone',\n",
       "       'Exterior2nd_Stucco', 'Exterior2nd_VinylSd', 'Exterior2nd_Wd Sdng',\n",
       "       'Exterior2nd_Wd Shng', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace',\n",
       "       'MasVnrType_None', 'MasVnrType_Stone', 'ExterQual_Ex',\n",
       "       'ExterQual_Fa', 'ExterQual_Gd', 'ExterQual_TA', 'ExterCond_Ex',\n",
       "       'ExterCond_Fa', 'ExterCond_Gd', 'ExterCond_Po', 'ExterCond_TA',\n",
       "       'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc',\n",
       "       'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood',\n",
       "       'BsmtQual_Ex', 'BsmtQual_Fa', 'BsmtQual_Gd', 'BsmtQual_None',\n",
       "       'BsmtQual_TA', 'BsmtCond_Fa', 'BsmtCond_Gd', 'BsmtCond_None',\n",
       "       'BsmtCond_Po', 'BsmtCond_TA', 'BsmtExposure_Av', 'BsmtExposure_Gd',\n",
       "       'BsmtExposure_Mn', 'BsmtExposure_No', 'BsmtExposure_None',\n",
       "       'BsmtFinType1_ALQ', 'BsmtFinType1_BLQ', 'BsmtFinType1_GLQ',\n",
       "       'BsmtFinType1_LwQ', 'BsmtFinType1_None', 'BsmtFinType1_Rec',\n",
       "       'BsmtFinType1_Unf', 'BsmtFinType2_ALQ', 'BsmtFinType2_BLQ',\n",
       "       'BsmtFinType2_GLQ', 'BsmtFinType2_LwQ', 'BsmtFinType2_None',\n",
       "       'BsmtFinType2_Rec', 'BsmtFinType2_Unf', 'Heating_Floor',\n",
       "       'Heating_GasA', 'Heating_GasW', 'Heating_Grav', 'Heating_OthW',\n",
       "       'Heating_Wall', 'HeatingQC_Ex', 'HeatingQC_Fa', 'HeatingQC_Gd',\n",
       "       'HeatingQC_Po', 'HeatingQC_TA', 'CentralAir_N', 'CentralAir_Y',\n",
       "       'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP',\n",
       "       'Electrical_Mix', 'Electrical_None', 'Electrical_SBrkr',\n",
       "       'KitchenQual_Ex', 'KitchenQual_Fa', 'KitchenQual_Gd',\n",
       "       'KitchenQual_None', 'KitchenQual_TA', 'Functional_Maj1',\n",
       "       'Functional_Maj2', 'Functional_Min1', 'Functional_Min2',\n",
       "       'Functional_Mod', 'Functional_None', 'Functional_Sev',\n",
       "       'Functional_Typ', 'FireplaceQu_Ex', 'FireplaceQu_Fa',\n",
       "       'FireplaceQu_Gd', 'FireplaceQu_None', 'FireplaceQu_Po',\n",
       "       'FireplaceQu_TA', 'GarageType_2Types', 'GarageType_Attchd',\n",
       "       'GarageType_Basment', 'GarageType_BuiltIn', 'GarageType_CarPort',\n",
       "       'GarageType_Detchd', 'GarageType_None', 'GarageFinish_Fin',\n",
       "       'GarageFinish_None', 'GarageFinish_RFn', 'GarageFinish_Unf',\n",
       "       'GarageQual_Ex', 'GarageQual_Fa', 'GarageQual_Gd',\n",
       "       'GarageQual_None', 'GarageQual_Po', 'GarageQual_TA',\n",
       "       'GarageCond_Ex', 'GarageCond_Fa', 'GarageCond_Gd',\n",
       "       'GarageCond_None', 'GarageCond_Po', 'GarageCond_TA',\n",
       "       'PavedDrive_N', 'PavedDrive_P', 'PavedDrive_Y', 'Fence_GdPrv',\n",
       "       'Fence_GdWo', 'Fence_MnPrv', 'Fence_MnWw', 'Fence_None',\n",
       "       'MiscFeature_Gar2', 'MiscFeature_None', 'MiscFeature_Othr',\n",
       "       'MiscFeature_Shed', 'MiscFeature_TenC', 'SaleType_COD',\n",
       "       'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI',\n",
       "       'SaleType_ConLw', 'SaleType_New', 'SaleType_None', 'SaleType_Oth',\n",
       "       'SaleType_WD', 'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family',\n",
       "       'SaleCondition_Normal', 'SaleCondition_Partial'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(X):, :]\n",
    "\n",
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n",
    "X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1453, 303) y (1453,) X_sub (1459, 303)\n"
     ]
    }
   ],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]#怎么判定的？\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "overfit.append('MSZoning_C (all)')\n",
    "\n",
    "X = X.drop(overfit, axis=1).copy()\n",
    "X_sub = X_sub.drop(overfit, axis=1).copy()\n",
    "\n",
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################## ML ########################################\n",
    "print('START ML', datetime.now(), )\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# rmsle\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "# build our model scoring function\n",
    "def cv_rmse(model):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y,\n",
    "                                    scoring=\"neg_mean_squared_error\",\n",
    "                                    cv=kfolds))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# setup models    \n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(),\n",
    "                      RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(),\n",
    "                      LassoCV(max_iter=1e7, alphas=alphas2,\n",
    "                              random_state=42, cv=kfolds))\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(),\n",
    "                           ElasticNetCV(max_iter=1e7, alphas=e_alphas,\n",
    "                                        cv=kfolds, l1_ratio=e_l1ratio))\n",
    "\n",
    "svr = make_pipeline(RobustScaler(),\n",
    "                    SVR(C=20, epsilon=0.008, gamma=0.0003, ))\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                max_depth=4, max_features='sqrt',\n",
    "                                min_samples_leaf=15, min_samples_split=10,\n",
    "                                loss='huber', random_state=42)\n",
    "\n",
    "lightgbm = LGBMRegressor(objective='regression',\n",
    "                         num_leaves=4,\n",
    "                         learning_rate=0.01,\n",
    "                         n_estimators=5000,\n",
    "                         max_bin=200,\n",
    "                         bagging_fraction=0.75,\n",
    "                         bagging_freq=5,\n",
    "                         bagging_seed=7,\n",
    "                         feature_fraction=0.2,\n",
    "                         feature_fraction_seed=7,\n",
    "                         verbose=-1,\n",
    "                         # min_data_in_leaf=2,\n",
    "                         # min_sum_hessian_in_leaf=11\n",
    "                         )\n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                       max_depth=3, min_child_weight=0,\n",
    "                       gamma=0, subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear', nthread=-1,\n",
    "                       scale_pos_weight=1, seed=27,\n",
    "                       reg_alpha=0.00006)\n",
    "\n",
    "# stack\n",
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet,\n",
    "                                            gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)\n",
    "\n",
    "print('TEST score on CV')\n",
    "\n",
    "score = cv_rmse(ridge)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lasso)\n",
    "print(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"GradientBoosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"Lightgbm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "print('START Fit')\n",
    "print(datetime.now(), 'StackingCVRegressor')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "print(datetime.now(), 'elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "print(datetime.now(), 'lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "print(datetime.now(), 'ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "print(datetime.now(), 'svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "print(datetime.now(), 'GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "print(datetime.now(), 'xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "print(datetime.now(), 'lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)\n",
    "\n",
    "\n",
    "def blend_models_predict(X=X):\n",
    "    return ((0.1* elastic_model_full_data.predict(X)) + \n",
    "            (0.1 * lasso_model_full_data.predict(X)) + \n",
    "            (0.05 * ridge_model_full_data.predict(X)) + \n",
    "            (0.1 * svr_model_full_data.predict(X)) + \n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))\n",
    "\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))\n",
    "print('MSE score on train data:')\n",
    "print(mean_squared_error(y, blend_models_predict(X)))\n",
    "print('MAE score on train data:')\n",
    "print(mean_absolute_error(np.expm1(y), np.floor(np.expm1(blend_models_predict(X)))))\n",
    "\n",
    "\n",
    "print('Predict submission', datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/all/sample_submission.csv')\n",
    "# submission = pd.read_csv(\".data/all/train.csv\")\n",
    "# train = pd.read_csv('./data/all/train.csv')\n",
    "submission.iloc[:, 1] = np.floor(np.expm1(blend_models_predict(X_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save submission 2019-03-20 22:16:04.257111\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv(\"House_price_submission_v17.csv\", index=False)\n",
    "print('Save submission', datetime.now(), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
